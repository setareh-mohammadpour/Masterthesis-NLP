# Exploring the Potential of Transformer-Based Models for Sentiment Analysis in Educational Reviews
## Description
This repository contains the implementation and evaluation of models for sentiment analysis in educational reviews. It compares traditional models like FastText with transformer-based architectures such as BERT, DistilBERT, RoBERTa-base, and RoBERTa-large.

## Features
- Evaluation of traditional and transformer-based models for binary sentiment classification.
- Analysis of computational time for each model using different GPUs.
- Preprocessing scripts for preparing the educational reviews dataset.
- Metrics such as accuracy, precision, recall, and F1-score for performance comparison.
- Training and validation performance visualization.
- 
